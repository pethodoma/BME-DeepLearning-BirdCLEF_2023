{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pethodoma/BME-DeepLearning-BirdCLEF_2023/blob/main/final_model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "dusJmczR6Bk3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "import shutil\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioNIgl0j6Q9d"
      },
      "outputs": [],
      "source": [
        "!wget -q -O training_files.zip https://www.dropbox.com/scl/fi/3il8m9feo2piqnsodwguh/atleast_50_png.zip?rlkey=9zipwrq01xv9r29n9xgcci6q8&dl=0\n",
        "!unzip -q 'training_files.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liEfitog6ShH"
      },
      "outputs": [],
      "source": [
        "def read_file_paths(main_directory):\n",
        "    main_directory = main_directory\n",
        "    file_paths = []\n",
        "\n",
        "    # go through all folders and get the paths of all .ogg audio files\n",
        "    for root, directories, files in os.walk(main_directory):\n",
        "        for file in files:\n",
        "            if file.endswith('.png'):\n",
        "                file_path = os.path.join(root, file)\n",
        "                file_paths.append(file_path)\n",
        "\n",
        "    # os.walk may not go in alphabetical order thus it needs to be sorted\n",
        "    file_paths.sort()\n",
        "    return file_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMT8kJ-N6WcR"
      },
      "outputs": [],
      "source": [
        "# Creating the dict with the numerical categories to each filepath\n",
        "df = pd.read_csv('atleast_50.csv')\n",
        "df['Category'] = range(len(df))\n",
        "# Creating the dictionary that maps the labels to the filepaths\n",
        "labelmapper = {filename: df[df['Bird'] == filename.split(os.path.sep)[-2]]['Category'].values[0] for filename in read_file_paths('spectrograms')}\n",
        "# Splitting the data\n",
        "filepaths = list(labelmapper.keys())\n",
        "labels = list(labelmapper.values())\n",
        "train_paths, test_valid_paths, train_labels,  test_valid_labels = train_test_split(filepaths, labels, test_size=0.2, random_state=42, stratify=labels)\n",
        "test_paths, valid_paths, _, _ = train_test_split(test_valid_paths, test_valid_labels, test_size=0.5, random_state=42, stratify=test_valid_labels)\n",
        "# Create directories for training and validation data\n",
        "os.makedirs('train', exist_ok=True)\n",
        "os.makedirs('test', exist_ok=True)\n",
        "os.makedirs('validation', exist_ok=True)\n",
        "# Creating the subdirectories with the bird names\n",
        "for bird in df['Bird']:\n",
        "    os.makedirs(os.path.join('train', bird), exist_ok=True)\n",
        "    os.makedirs(os.path.join('test', bird), exist_ok=True)\n",
        "    os.makedirs(os.path.join('validation', bird), exist_ok=True)\n",
        "# Moving the files to the train and validation folders\n",
        "for filepath in train_paths:\n",
        "    shutil.move(filepath, os.path.join('train', filepath.split(os.path.sep)[-2], filepath.split(os.path.sep)[-1]))\n",
        "for filepath in test_paths:\n",
        "    shutil.move(filepath, os.path.join('test', filepath.split(os.path.sep)[-2], filepath.split(os.path.sep)[-1]))\n",
        "for filepath in valid_paths:\n",
        "    shutil.move(filepath, os.path.join('validation', filepath.split(os.path.sep)[-2], filepath.split(os.path.sep)[-1]))\n",
        "# Deleting the original directory\n",
        "shutil.rmtree('spectrograms')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRLisT3y6fiM",
        "outputId": "e117b8eb-b189-49c3-b9f4-48557cb45d53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 66200 images belonging to 192 classes.\n",
            "Found 8275 images belonging to 192 classes.\n"
          ]
        }
      ],
      "source": [
        "batch_size = 128\n",
        "# Create an ImageDataGenerator for training data\n",
        "# Datagenerator for training\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    'train',\n",
        "    target_size=(128, 312),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "# Datagenerator for validation\n",
        "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    'test',\n",
        "    target_size=(128, 312),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7AVE5e76i8_"
      },
      "outputs": [],
      "source": [
        "# Get class indices from the generator\n",
        "class_indices = train_generator.class_indices\n",
        "class_labels = list(class_indices.values())\n",
        "# Calculate class weights\n",
        "class_weights = class_weight.compute_class_weight('balanced', classes=class_labels, y=train_generator.classes)\n",
        "# Map class weights\n",
        "class_weights_dict = {}\n",
        "for i, class_label in enumerate(class_labels):\n",
        "    class_weights_dict[class_label] = class_weights[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wW1T7loe6jiG"
      },
      "outputs": [],
      "source": [
        "# Defining callbacks\n",
        "es = tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss', verbose=1)\n",
        "mc = tf.keras.callbacks.ModelCheckpoint(filepath='best_model.h5', save_best_only=True, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYxvxG0G1qmL",
        "outputId": "8bcc2514-781e-4dc3-96f0-c84c63436899"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras_tuner\n",
            "  Downloading keras_tuner-1.4.6-py3-none-any.whl (128 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/128.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/128.9 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.9/128.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (2.14.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (23.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras_tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2023.11.17)\n",
            "Installing collected packages: kt-legacy, keras_tuner\n",
            "Successfully installed keras_tuner-1.4.6 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usrJqoHq1c3O",
        "outputId": "480e3910-3915-4766-a65d-0c03d463bdc0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-511beda95521>:5: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  from kerastuner.tuners import RandomSearch\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from kerastuner.tuners import RandomSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMSdDPtw2hOw"
      },
      "outputs": [],
      "source": [
        "num_classes = 192"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22g34E4Q0yyO"
      },
      "outputs": [],
      "source": [
        "# Function to help hyperparameter optimization\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(hp.Int('conv1_units', min_value=16, max_value=64, step=8), (5, 5), activation='relu', input_shape=(128, 312, 3)))\n",
        "    model.add(Dropout(hp.Float('dropout_1', min_value=0.2, max_value=0.5, step=0.1)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(hp.Int('conv2_units', min_value=8, max_value=32, step=8), (5, 5), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(hp.Float('dropout_2', min_value=0.2, max_value=0.5, step=0.1)))\n",
        "\n",
        "    model.add(Dense(hp.Int('dense_units', min_value=64, max_value=256, step=32), activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy', 'categorical_crossentropy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vIhsl0u1Ch4",
        "outputId": "d6f0e009-3631-497c-aa4a-c8abe0db34e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 5 Complete [00h 32m 14s]\n",
            "val_accuracy: 0.29631420969963074\n",
            "\n",
            "Best val_accuracy So Far: 0.46308156847953796\n",
            "Total elapsed time: 02h 33m 10s\n"
          ]
        }
      ],
      "source": [
        "# Using RandomSearch and running 5 trials, with each trial having 5 epochs\n",
        "num_epochs = 5\n",
        "\n",
        "# Configuring the tuner\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,\n",
        "    directory='keras_tuner_logs',\n",
        ")\n",
        "\n",
        "# Searching the best parameters\n",
        "tuner.search(train_generator,\n",
        "             epochs=num_epochs,\n",
        "             validation_data=valid_generator,\n",
        "             callbacks=[es, mc],\n",
        "             class_weight=class_weights_dict,\n",
        "             workers=6,\n",
        "             use_multiprocessing=True)\n",
        "\n",
        "# The best found hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# Building the final model\n",
        "final_model = tuner.hypermodel.build(best_hps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOzWdyvcgDH4",
        "outputId": "ac06174b-7fd1-47d7-d645-e57e47fdad02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 124, 308, 32)      2432      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 124, 308, 32)      0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 62, 154, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 58, 150, 16)       12816     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 29, 75, 16)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 34800)             0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 34800)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 224)               7795424   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 192)               43200     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7853872 (29.96 MB)\n",
            "Trainable params: 7853872 (29.96 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# The best found parameters were good enough for 0.46 validation accuracy after 5 epochs\n",
        "final_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZ7sBzrsgQ2i"
      },
      "outputs": [],
      "source": [
        "num_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWJwn9lPgKsO",
        "outputId": "bd7924d7-89bc-41ff-e6db-4d8d1288f8e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "518/518 [==============================] - 347s 666ms/step - loss: 4.1554 - accuracy: 0.1466 - categorical_crossentropy: 4.2170 - precision_1: 0.7309 - recall_1: 0.0415 - val_loss: 3.4099 - val_accuracy: 0.2830 - val_categorical_crossentropy: 3.4099 - val_precision_1: 0.8438 - val_recall_1: 0.0777\n",
            "Epoch 2/10\n",
            "518/518 [==============================] - 353s 675ms/step - loss: 2.4849 - accuracy: 0.3606 - categorical_crossentropy: 2.9259 - precision_1: 0.7614 - recall_1: 0.1935 - val_loss: 2.9837 - val_accuracy: 0.3403 - val_categorical_crossentropy: 2.9837 - val_precision_1: 0.7398 - val_recall_1: 0.1594\n",
            "Epoch 3/10\n",
            "518/518 [==============================] - 361s 690ms/step - loss: 1.3893 - accuracy: 0.5123 - categorical_crossentropy: 2.1540 - precision_1: 0.7905 - recall_1: 0.3757 - val_loss: 2.6672 - val_accuracy: 0.4022 - val_categorical_crossentropy: 2.6672 - val_precision_1: 0.7432 - val_recall_1: 0.2231\n",
            "Epoch 4/10\n",
            "518/518 [==============================] - 360s 692ms/step - loss: 0.7662 - accuracy: 0.6305 - categorical_crossentropy: 1.5763 - precision_1: 0.8289 - recall_1: 0.5297 - val_loss: 2.5156 - val_accuracy: 0.4404 - val_categorical_crossentropy: 2.5156 - val_precision_1: 0.6865 - val_recall_1: 0.3185\n",
            "Epoch 5/10\n",
            "518/518 [==============================] - 396s 761ms/step - loss: 0.4727 - accuracy: 0.7040 - categorical_crossentropy: 1.2332 - precision_1: 0.8463 - recall_1: 0.6265 - val_loss: 2.3927 - val_accuracy: 0.4864 - val_categorical_crossentropy: 2.3927 - val_precision_1: 0.6892 - val_recall_1: 0.3949\n",
            "Epoch 6/10\n",
            "518/518 [==============================] - 362s 692ms/step - loss: 0.3049 - accuracy: 0.7649 - categorical_crossentropy: 0.9410 - precision_1: 0.8716 - recall_1: 0.7066 - val_loss: 2.3721 - val_accuracy: 0.5039 - val_categorical_crossentropy: 2.3721 - val_precision_1: 0.6797 - val_recall_1: 0.4153\n",
            "Epoch 7/10\n",
            "518/518 [==============================] - 399s 764ms/step - loss: 0.2370 - accuracy: 0.7969 - categorical_crossentropy: 0.8013 - precision_1: 0.8827 - recall_1: 0.7475 - val_loss: 2.5974 - val_accuracy: 0.4856 - val_categorical_crossentropy: 2.5974 - val_precision_1: 0.6289 - val_recall_1: 0.4074\n",
            "Epoch 8/10\n",
            "518/518 [==============================] - 359s 688ms/step - loss: 0.2170 - accuracy: 0.8102 - categorical_crossentropy: 0.7320 - precision_1: 0.8863 - recall_1: 0.7657 - val_loss: 2.6106 - val_accuracy: 0.4926 - val_categorical_crossentropy: 2.6106 - val_precision_1: 0.6243 - val_recall_1: 0.4228\n",
            "Epoch 9/10\n",
            "518/518 [==============================] - 369s 707ms/step - loss: 0.1722 - accuracy: 0.8342 - categorical_crossentropy: 0.6331 - precision_1: 0.8960 - recall_1: 0.7967 - val_loss: 2.6036 - val_accuracy: 0.5299 - val_categorical_crossentropy: 2.6036 - val_precision_1: 0.6520 - val_recall_1: 0.4661\n",
            "Epoch 10/10\n",
            "518/518 [==============================] - 361s 692ms/step - loss: 0.1433 - accuracy: 0.8578 - categorical_crossentropy: 0.5328 - precision_1: 0.9092 - recall_1: 0.8248 - val_loss: 2.6707 - val_accuracy: 0.5177 - val_categorical_crossentropy: 2.6707 - val_precision_1: 0.6408 - val_recall_1: 0.4576\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# Training the model with the best found parameters, for 10 epochs\n",
        "final_model.fit(train_generator,\n",
        "                epochs=num_epochs,\n",
        "                validation_data=valid_generator,\n",
        "                class_weight=class_weights_dict,\n",
        "                workers=6,\n",
        "                use_multiprocessing=True)\n",
        "\n",
        "# Saving the final model\n",
        "# We could reach almost .53 validation accuracy with this model\n",
        "final_model.save('final_model.h5')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}